{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b31e834",
   "metadata": {},
   "source": [
    "# Analysis of the inferred image embeddings\n",
    "\n",
    "In this notebook we assess the inferred image embeddings for the previosuly determined impactful gene perturbation settings. To this end, we will use the image embeddings computed during the training of the convolutional neural network in the 4-fold Group CV setup.\n",
    "\n",
    "---\n",
    "\n",
    "## 0. Environmental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e1300",
   "metadata": {},
   "source": [
    "First, we read in the required software packages and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster import hierarchy as hc\n",
    "from scipy.spatial.distance import pdist, euclidean, cosine\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import squareform\n",
    "import sys\n",
    "from sklearn.metrics import (\n",
    "    mutual_info_score,\n",
    "    adjusted_mutual_info_score,\n",
    "    adjusted_rand_score,\n",
    "    rand_score,\n",
    "    v_measure_score,\n",
    "    normalized_mutual_info_score,\n",
    ")\n",
    "import matplotlib as mpl\n",
    "from collections import Counter\n",
    "from yellowbrick.cluster.elbow import kelbow_visualizer\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from IPython.display import Image\n",
    "from statannot import add_stat_annotation\n",
    "import ot\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "from src.utils.notebooks.ppi.embedding import *\n",
    "from src.utils.notebooks.images.embedding import *\n",
    "from src.utils.notebooks.translation.analysis import *\n",
    "from src.utils.basic.io import get_genesets_from_gmt_file\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 600\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95728d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_cluster_topk(reg_nn_dict, struct_nn_dict, cluster_df):\n",
    "    struct_topks = []\n",
    "    reg_topks = []\n",
    "    samples = []\n",
    "    for sample in reg_nn_dict.keys():\n",
    "        reg_nns = reg_nn_dict[sample]\n",
    "        struct_nns = struct_nn_dict[sample]\n",
    "        cluster = np.array(cluster_df.loc[sample])[0]\n",
    "        n_cluster_samples = len(cluster_df.loc[cluster_df.cluster == cluster])\n",
    "        if n_cluster_samples < 2:\n",
    "            continue\n",
    "        samples.append(sample)\n",
    "        sample_struct_topks = [0]\n",
    "        sample_reg_topks = [0]\n",
    "        for i in range(1, len(reg_nns)):\n",
    "            reg_nn_cluster = np.array(cluster_df.loc[reg_nns[i]])[0]\n",
    "            struct_nn_cluster = np.array(cluster_df.loc[struct_nns[i]])[0]\n",
    "            sample_struct_topks.append(\n",
    "                sample_struct_topks[-1] + int(struct_nn_cluster == cluster)\n",
    "            )\n",
    "            sample_reg_topks.append(\n",
    "                sample_reg_topks[-1] + int(reg_nn_cluster == cluster)\n",
    "            )\n",
    "        struct_topks.append(np.array(sample_struct_topks[1:]) / (n_cluster_samples - 1))\n",
    "        reg_topks.append(np.array(sample_reg_topks[1:]) / (n_cluster_samples - 1))\n",
    "    return samples, np.array(struct_topks), np.array(reg_topks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_dict(data, metric=\"euclidean\"):\n",
    "    samples = np.array(data.index)\n",
    "    nn = NearestNeighbors(n_neighbors=len(data), metric=metric)\n",
    "    sample_neighbor_dict = {}\n",
    "    nn.fit(np.array(data))\n",
    "    for sample in samples:\n",
    "        if metric == \"precomputed\":\n",
    "            query = np.zeros((1, len(data)))\n",
    "            query[0, np.where(samples == sample)[0]] = 1\n",
    "            pred_idx = nn.kneighbors(query, return_distance=False)[0]\n",
    "        pred_idx = nn.kneighbors(\n",
    "            np.array(data.loc[sample]).reshape(1, -1), return_distance=False\n",
    "        )[0]\n",
    "        sample_neighbor_dict[sample] = samples[pred_idx]\n",
    "    return sample_neighbor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27683856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emd_for_embs(embs, label_col, metric=\"euclidean\"):\n",
    "    targets = np.unique(embs.loc[:, label_col])\n",
    "    n_targets = len(targets)\n",
    "    wd_mtx = np.infty * np.ones((n_targets, n_targets))\n",
    "    for i in tqdm(range(n_targets), desc=\"Compute EMD\"):\n",
    "        source = targets[i]\n",
    "        xs = np.array(embs.loc[embs.loc[:, label_col] == source]._get_numeric_data())\n",
    "        ns = len(xs)\n",
    "        ps = np.ones((ns,)) / ns\n",
    "        for j in range(i, n_targets):\n",
    "            target = targets[j]\n",
    "            if source == target:\n",
    "                wd_st = 0\n",
    "            else:\n",
    "                xt = np.array(\n",
    "                    embs.loc[embs.loc[:, label_col] == target]._get_numeric_data()\n",
    "                )\n",
    "                nt = len(xt)\n",
    "                pt = np.ones((nt,)) / nt\n",
    "                m = ot.dist(xs, xt, metric=metric)\n",
    "                m = m / m.max()\n",
    "                wd_st = ot.emd2(ps, pt, m, numItermax=1e9)\n",
    "            wd_mtx[i, j] = wd_st\n",
    "            wd_mtx[j, i] = wd_st\n",
    "    wd_df = pd.DataFrame(wd_mtx, columns=list(targets), index=list(targets))\n",
    "    return wd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c1c0f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e19a5a",
   "metadata": {},
   "source": [
    "Second, we read in the data that describes the latent embeddings of the individual images part of the respective held-out sets in the CV setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../../../data/experiments/image_embeddings/specificity_target_emb_cv_strat/final_1024/\"\n",
    "\n",
    "all_latents = []\n",
    "\n",
    "for i in range(4):\n",
    "    latents = pd.read_hdf(root_dir + \"fold_{}/\".format(i) + \"test_latents.h5\")\n",
    "    latents[\"fold\"] = \"fold_{}\".format(i)\n",
    "    all_latents.append(latents)\n",
    "latents = pd.concat(all_latents)\n",
    "print(\"Read in latent embeddings of shape: {}\".format(np.array(latents).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753dd42",
   "metadata": {},
   "source": [
    "We will decode the numeric class labels to identify which regulator each embedding corresponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362af25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    \"AKT1S1\": 0,\n",
    "    \"ATF4\": 1,\n",
    "    \"BAX\": 2,\n",
    "    \"BCL2L11\": 3,\n",
    "    \"BRAF\": 4,\n",
    "    \"CASP8\": 5,\n",
    "    \"CDC42\": 6,\n",
    "    \"CDKN1A\": 7,\n",
    "    \"CEBPA\": 8,\n",
    "    \"CREB1\": 9,\n",
    "    \"CXXC4\": 10,\n",
    "    \"DIABLO\": 11,\n",
    "    \"E2F1\": 12,\n",
    "    \"ELK1\": 13,\n",
    "    \"EMPTY\": 14,\n",
    "    \"ERG\": 15,\n",
    "    \"FGFR3\": 16,\n",
    "    \"FOXO1\": 17,\n",
    "    \"GLI1\": 18,\n",
    "    \"HRAS\": 19,\n",
    "    \"IRAK4\": 20,\n",
    "    \"JUN\": 21,\n",
    "    \"MAP2K3\": 22,\n",
    "    \"MAP3K2\": 23,\n",
    "    \"MAP3K5\": 24,\n",
    "    \"MAP3K9\": 25,\n",
    "    \"MAPK7\": 26,\n",
    "    \"MOS\": 27,\n",
    "    \"MYD88\": 28,\n",
    "    \"PIK3R2\": 29,\n",
    "    \"PRKACA\": 30,\n",
    "    \"PRKCE\": 31,\n",
    "    \"RAF1\": 32,\n",
    "    \"RELB\": 33,\n",
    "    \"RHOA\": 34,\n",
    "    \"SMAD4\": 35,\n",
    "    \"SMO\": 36,\n",
    "    \"SRC\": 37,\n",
    "    \"SREBF1\": 38,\n",
    "    \"TRAF2\": 39,\n",
    "    \"TSC2\": 40,\n",
    "    \"WWTR1\": 41,\n",
    "}\n",
    "label_dict = dict(zip(list(label_dict.values()), list(label_dict.keys())))\n",
    "latents.loc[:, \"labels\"] = latents.loc[:, \"labels\"].map(label_dict)\n",
    "\n",
    "oe_targets = set(list(latents.loc[:, \"labels\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e7194",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Visualization of the embeddings\n",
    "\n",
    "Next, we will visualize the individual image embeddings. To this end, we will use UMAP to compute a 2D representation of the individual embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7959c0",
   "metadata": {},
   "source": [
    "### 2.1. Overview of the joint image embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fdc1e5",
   "metadata": {},
   "source": [
    "As a first step we show that as expected the image embeddings differ between folds which is expected by design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c02058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embs = plot_struct_embs_cv(latents, random_state=1234, normalize_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4612feb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2. Visualization of individual perturbation settings.\n",
    "\n",
    "We now once more will plot the image embeddings of a given gene perturbation against a background established from all other gene perturbation and the control condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f0ee8",
   "metadata": {},
   "source": [
    "To this end, we will randomly select the image embeddigns computed for the first fold of the 4-fold Group K-Fold setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbd344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embs_0 = plot_struct_embs_cv(latents, random_state=1234, folds=[\"fold_0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aebc7fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpl.style.use(\"default\")\n",
    "mpl.rcParams[\"figure.dpi\"] = 600\n",
    "\n",
    "# for gene in np.unique(embs_0.label):\n",
    "for gene in [\"EMPTY\", \"JUN\", \"MAP3K9\", \"RAF1\"]:\n",
    "    geneset = [gene]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=[8, 6])\n",
    "    ax.scatter(\n",
    "        np.array(embs_0.loc[~embs_0.label.isin(geneset), \"umap_0\"]),\n",
    "        np.array(embs_0.loc[~embs_0.label.isin(geneset), \"umap_1\"]),\n",
    "        c=\"silver\",\n",
    "        alpha=0.1,\n",
    "        label=\"other\",\n",
    "        s=3,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        np.array(embs_0.loc[embs_0.label.isin(geneset), \"umap_0\"]),\n",
    "        np.array(embs_0.loc[embs_0.label.isin(geneset), \"umap_1\"]),\n",
    "        # label=geneset[0],\n",
    "        s=3,\n",
    "        alpha=1,\n",
    "        color=\"r\",\n",
    "        label=gene,\n",
    "    )\n",
    "    #     ax.legend(loc=\"lower right\")\n",
    "    #     handles, labels = ax.get_legend_handles_labels()\n",
    "    #     ax.legend(\n",
    "    #         handles=list(handles)[::-1],\n",
    "    #         labels=list(labels)[::-1],\n",
    "    #         loc=\"lower right\",\n",
    "    #         prop=dict(size=18),\n",
    "    #     )\n",
    "    #     #     for lh in ax.get_legend().legendHandles:\n",
    "    #     #         lh.set_alpha(1)\n",
    "    #     #         lh._sizes = [140]\n",
    "    # ax.get_legend().set_title(\"Condition\", prop={\"size\": \"20\"})\n",
    "    #     ax.get_legend().set_title(\"\")\n",
    "    # ax.set_xlabel(\"umap_0\", size=18)\n",
    "    # ax.set_ylabel(\"umap_1\", size=18)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.xticks(size=14)\n",
    "    plt.yticks(size=14)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c14116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
