{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76b06e7",
   "metadata": {},
   "source": [
    "<font size=18> EDA of the morphological profiles for the JUMP data set </font>\n",
    "\n",
    "---\n",
    "\n",
    "This notebook serves to scrape the morphological profiles for the different conditions from the JUMP data set and analyze the ones corresponding to selected overexpression conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371a61d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5773d2a",
   "metadata": {},
   "source": [
    "# Environmental setup\n",
    "\n",
    "First, we load all required software packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    cross_validate,\n",
    "    StratifiedGroupKFold,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "from venn import venn\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import pdist\n",
    "from numpy.linalg import svd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 600\n",
    "\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0bbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_null_space_projection(\n",
    "    embeddings,\n",
    "    batch_labels,\n",
    "    bac_threshold=0.3,\n",
    "    max_iter=200,\n",
    "    max_iter_clf=1000,\n",
    "    random_state=1234,\n",
    "    n_jobs=1,\n",
    "    balance_batches=False,\n",
    "    n_samples_per_batch=None,\n",
    "):\n",
    "    batch_labels = LabelEncoder().fit_transform(batch_labels)\n",
    "    b = batch_labels.max() + 1\n",
    "\n",
    "    if balance_batches:\n",
    "        ru = RandomUnderSampler(random_state=random_state)\n",
    "        sample_idc, _ = ru.fit_resample(\n",
    "            np.array(list(range(len(batch_labels)))).reshape(-1, 1), batch_labels\n",
    "        )\n",
    "        sample_idc = sample_idc.ravel()\n",
    "        train_batch_labels = batch_labels[sample_idc]\n",
    "        train_embeddings = embeddings[sample_idc]\n",
    "\n",
    "        if n_samples_per_batch is not None:\n",
    "            batch_sample_count = dict(zip(list(range(b)), [n_samples_per_batch] * b))\n",
    "            ru = RandomUnderSampler(\n",
    "                random_state=random_state, sampling_strategy=batch_sample_count\n",
    "            )\n",
    "            sample_idc, _ = ru.fit_resample(\n",
    "                np.array(list(range(len(train_batch_labels)))).reshape(-1, 1),\n",
    "                train_batch_labels,\n",
    "            )\n",
    "            sample_idc = sample_idc.ravel()\n",
    "            train_batch_labels = train_batch_labels[sample_idc]\n",
    "            train_embeddings = train_embeddings[sample_idc]\n",
    "    else:\n",
    "        train_batch_labels = batch_labels\n",
    "        train_embeddings = embeddings\n",
    "\n",
    "    print(train_embeddings.shape)\n",
    "\n",
    "    bacs = []\n",
    "    for i in tqdm(range(max_iter)):\n",
    "        clf = LogisticRegression(\n",
    "            class_weight=\"balanced\",\n",
    "            multi_class=\"multinomial\",\n",
    "            solver=\"lbfgs\",\n",
    "            n_jobs=n_jobs,\n",
    "            penalty=\"l2\",\n",
    "            max_iter=max_iter_clf,\n",
    "        )\n",
    "\n",
    "        bac = cross_val_score(\n",
    "            clf,\n",
    "            train_embeddings,\n",
    "            train_batch_labels,\n",
    "            scoring=\"balanced_accuracy\",\n",
    "            cv=StratifiedKFold(n_splits=3),\n",
    "        ).mean()\n",
    "        bacs.append(bac)\n",
    "        clf.fit(train_embeddings, train_batch_labels)\n",
    "        weights = clf.coef_\n",
    "        _, _, vt = svd(weights, full_matrices=True)\n",
    "        v_tilde = vt[b:, :].transpose()\n",
    "        embeddings = np.matmul(embeddings, v_tilde)\n",
    "        train_embeddings = np.matmul(train_embeddings, v_tilde)\n",
    "\n",
    "        if bac < bac_threshold:\n",
    "            break\n",
    "    return embeddings, bacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_clustering_to_rohban(\n",
    "    jump_mean_embeddings,\n",
    "    rohban_mean_embeddings,\n",
    "    metric=\"euclidean\",\n",
    "    figsize=[12, 12],\n",
    "    method=\"complete\",\n",
    "):\n",
    "    shared_targets = list(\n",
    "        set(jump_mean_embeddings.index).intersection(rohban_mean_embeddings.index)\n",
    "    )\n",
    "    print(shared_targets)\n",
    "    jump_dist = pd.DataFrame(\n",
    "        squareform(pdist(jump_mean_embeddings.loc[shared_targets], metric=metric)),\n",
    "        index=shared_targets,\n",
    "        columns=shared_targets,\n",
    "    )\n",
    "    rohban_dist = pd.DataFrame(\n",
    "        squareform(pdist(rohban_mean_embeddings.loc[shared_targets], metric=metric)),\n",
    "        index=shared_targets,\n",
    "        columns=shared_targets,\n",
    "    )\n",
    "    fig = sns.clustermap(jump_dist, figsize=figsize, cmap=\"viridis\", method=method)\n",
    "    fig.fig.suptitle(\"JUMP embeddings\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    gig = sns.clustermap(rohban_dist, figsize=figsize, cmap=\"inferno\", method=method)\n",
    "    gig.fig.suptitle(\"Rohban embeddings\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ac01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_statistics(\n",
    "    embeddings,\n",
    "    batch_col=\"Metadata_Batch\",\n",
    "    label_col=\"Metadata_Symbol\",\n",
    "    ctrl_label=\"EMPTY\",\n",
    "):\n",
    "    ctrl_means = (\n",
    "        embeddings.loc[embeddings.loc[:, label_col] == ctrl_label]\n",
    "        .groupby(batch_col)\n",
    "        .mean(numeric_only=True)\n",
    "    )\n",
    "    ctrl_stds = (\n",
    "        embeddings.loc[embeddings.loc[:, label_col] == ctrl_label]\n",
    "        .groupby(batch_col)\n",
    "        .std(numeric_only=True)\n",
    "    )\n",
    "    return ctrl_means, ctrl_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_within_batch_normalization(\n",
    "    embeddings,\n",
    "    batch_col=\"Metadata_Batch\",\n",
    "    label_col=\"Metadata_Symbol\",\n",
    "    ctrl_label=\"EMPTY\",\n",
    "):\n",
    "    ctrl_means, ctrl_stds = compute_batch_statistics(\n",
    "        embeddings, batch_col=batch_col, label_col=label_col, ctrl_label=ctrl_label\n",
    "    )\n",
    "    print(\"Statistics computed.\")\n",
    "    scaled_embeddings = embeddings.copy()\n",
    "    for batch in tqdm(set(scaled_embeddings.loc[:, batch_col])):\n",
    "        for col in ctrl_means.columns:\n",
    "            scaled_embeddings.loc[scaled_embeddings.loc[:, batch_col] == batch, col] = (\n",
    "                np.array(\n",
    "                    scaled_embeddings.loc[\n",
    "                        scaled_embeddings.loc[:, batch_col] == batch, col\n",
    "                    ]\n",
    "                )\n",
    "                - ctrl_means.loc[batch, col]\n",
    "            )\n",
    "            scaled_embeddings.loc[scaled_embeddings.loc[:, batch_col] == batch, col] = (\n",
    "                np.array(\n",
    "                    scaled_embeddings.loc[\n",
    "                        scaled_embeddings.loc[:, batch_col] == batch, col\n",
    "                    ]\n",
    "                )\n",
    "                / ctrl_stds.loc[batch, col]\n",
    "            )\n",
    "    return scaled_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5619c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "impactful_conditions = list(\n",
    "    {\n",
    "        \"AKT1S1\": 0,\n",
    "        \"ATF4\": 1,\n",
    "        \"BAX\": 2,\n",
    "        \"BCL2L11\": 3,\n",
    "        \"BRAF\": 4,\n",
    "        \"CASP8\": 5,\n",
    "        \"CDC42\": 6,\n",
    "        \"CDKN1A\": 7,\n",
    "        \"CEBPA\": 8,\n",
    "        \"CREB1\": 9,\n",
    "        \"CXXC4\": 10,\n",
    "        \"DIABLO\": 11,\n",
    "        \"E2F1\": 12,\n",
    "        \"ELK1\": 13,\n",
    "        \"EMPTY\": 14,\n",
    "        \"ERG\": 15,\n",
    "        \"FGFR3\": 16,\n",
    "        \"FOXO1\": 17,\n",
    "        \"GLI1\": 18,\n",
    "        \"HRAS\": 19,\n",
    "        \"IRAK4\": 20,\n",
    "        \"JUN\": 21,\n",
    "        \"MAP2K3\": 22,\n",
    "        \"MAP3K2\": 23,\n",
    "        \"MAP3K5\": 24,\n",
    "        \"MAP3K9\": 25,\n",
    "        \"MAPK7\": 26,\n",
    "        \"MOS\": 27,\n",
    "        \"MYD88\": 28,\n",
    "        \"PIK3R2\": 29,\n",
    "        \"PRKACA\": 30,\n",
    "        \"PRKCE\": 31,\n",
    "        \"RAF1\": 32,\n",
    "        \"RELB\": 33,\n",
    "        \"RHOA\": 34,\n",
    "        \"SMAD4\": 35,\n",
    "        \"SMO\": 36,\n",
    "        \"SRC\": 37,\n",
    "        \"SREBF1\": 38,\n",
    "        \"TRAF2\": 39,\n",
    "        \"TSC2\": 40,\n",
    "        \"WWTR1\": 41,\n",
    "    }.keys()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_output_dir = \"../../../data/experiments/jump/images/embedding/embeddings\"\n",
    "os.makedirs(emb_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e3e8c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Get profile data\n",
    "\n",
    "As a next step we will use the boto3 package to scrape all deposited profile data from the AWS S3 bucket that contains the JUMP data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91d308",
   "metadata": {},
   "source": [
    "## Download profiles\n",
    "\n",
    "All profiles are deposited as .parquet files, we will thus screen for all data objects in the bucket that contain such a file ending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97204c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../../../data/resources/images/jump/profiles\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# s3_client = boto3.client(\"s3\", config=Config(signature_version=UNSIGNED))\n",
    "# objects = s3_client.list_objects_v2(\n",
    "#     Bucket=\"cellpainting-gallery\", Prefix=\"cpg0016-jump/source_3/workspace/profiles/\"\n",
    "# )\n",
    "# for obj in tqdm(objects[\"Contents\"]):\n",
    "#     path = obj[\"Key\"]\n",
    "#     entries = path.split(\"/\")\n",
    "#     source = entries[1]\n",
    "#     batch = entries[4]\n",
    "#     plate_file = entries[-1]\n",
    "#     s3_client.download_file(\n",
    "#         \"cellpainting-gallery\",\n",
    "#         obj[\"Key\"],\n",
    "#         os.path.join(output_dir, \"_\".join([source, batch, plate_file])),\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e11f6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Read in profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8fa594",
   "metadata": {},
   "source": [
    "Having downloaded all profile data, we will now read those and append the gene symbol information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9617e8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_morph_profiles = []\n",
    "for file in tqdm(os.listdir(output_dir)):\n",
    "    all_morph_profiles.append(pd.read_parquet(os.path.join(output_dir, file)))\n",
    "morph_profiles = pd.concat(all_morph_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cca0cf",
   "metadata": {},
   "source": [
    "The respective metadata can be obtained from previously downloaded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data = pd.read_csv(\"../../../data/resources/images/jump/metadata/well.csv\")\n",
    "orf_data = pd.read_csv(\"../../../data/resources/images/jump/metadata/orf.csv\")\n",
    "plate_data = pd.read_csv(\"../../../data/resources/images/jump/metadata/plate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa077eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_orf_data = well_data.merge(\n",
    "    orf_data, right_on=\"Metadata_JCP2022\", left_on=\"Metadata_JCP2022\", how=\"inner\"\n",
    ")\n",
    "all_orf_data = all_orf_data.merge(\n",
    "    plate_data.loc[:, [\"Metadata_Plate\", \"Metadata_Batch\", \"Metadata_PlateType\"]],\n",
    "    right_on=\"Metadata_Plate\",\n",
    "    left_on=\"Metadata_Plate\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f75c4",
   "metadata": {},
   "source": [
    "We will now combine the two datasets to construct a joint profile data set that contains the derived morphological profiles for the different overexpression conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e225fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_profiles[\"key\"] = (\n",
    "    morph_profiles[\"Metadata_Source\"]\n",
    "    + \"_\"\n",
    "    + morph_profiles[\"Metadata_Plate\"]\n",
    "    + \"_\"\n",
    "    + morph_profiles[\"Metadata_Well\"]\n",
    ")\n",
    "all_orf_data[\"key\"] = (\n",
    "    all_orf_data[\"Metadata_Source\"]\n",
    "    + \"_\"\n",
    "    + all_orf_data[\"Metadata_Plate\"]\n",
    "    + \"_\"\n",
    "    + all_orf_data[\"Metadata_Well\"]\n",
    ")\n",
    "\n",
    "selected_cols = [\"key\", \"Metadata_Batch\", \"Metadata_Symbol\"]\n",
    "morph_profiles = morph_profiles.merge(\n",
    "    all_orf_data.loc[:, selected_cols], on=\"key\", how=\"inner\"\n",
    ")\n",
    "morph_profiles = morph_profiles.drop(columns=[\"key\"])\n",
    "morph_profiles.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9badbc2c",
   "metadata": {},
   "source": [
    "In alignment with our analyses using directly the images, we define the condition using a \"BFP\" treatment as the control condition which we label as \"EMPTY\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24afdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_profiles.loc[morph_profiles.Metadata_Symbol == \"BFP\", \"Metadata_Symbol\"] = \"EMPTY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb04cea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Read in other data\n",
    "\n",
    "In addition to the morphological profiles from the JUMP data set, we now also read in the profiles we obtained from using our CNN encoder trained and evaluated on the images from the JUMP data set, as well as the image embeddings obtained for the dataset from Rohban et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_img_embs = pd.read_hdf(\n",
    "    \"../../../data/experiments/jump/images/embedding/specificity_target_emb_cv_strat/fold_0/nuclei_regions/test_latents.h5\"\n",
    ")\n",
    "label_dict = {\n",
    "    \"AKT1S1\": 0,\n",
    "    \"ATF4\": 1,\n",
    "    \"BAX\": 2,\n",
    "    \"BCL2L11\": 3,\n",
    "    \"BRAF\": 4,\n",
    "    \"CASP8\": 5,\n",
    "    \"CDKN1A\": 6,\n",
    "    \"CREB1\": 7,\n",
    "    \"DIABLO\": 8,\n",
    "    \"ELK1\": 9,\n",
    "    \"EMPTY\": 10,\n",
    "    \"ERG\": 11,\n",
    "    \"FGFR3\": 12,\n",
    "    \"HRAS\": 13,\n",
    "    \"IRAK4\": 14,\n",
    "    \"JUN\": 15,\n",
    "    \"MAP3K2\": 16,\n",
    "    \"MAP3K5\": 17,\n",
    "    \"MAP3K9\": 18,\n",
    "    \"MYD88\": 19,\n",
    "    \"PIK3R2\": 20,\n",
    "    \"PRKACA\": 21,\n",
    "    \"PRKCE\": 22,\n",
    "    \"RAF1\": 23,\n",
    "    \"RELB\": 24,\n",
    "    \"RHOA\": 25,\n",
    "    \"SMAD4\": 26,\n",
    "    \"SRC\": 27,\n",
    "    \"SREBF1\": 28,\n",
    "    \"TRAF2\": 29,\n",
    "    \"TSC2\": 30,\n",
    "    \"WWTR1\": 31,\n",
    "    \"ALOX5\": 32,\n",
    "    \"AMPH\": 33,\n",
    "    \"AQP1\": 34,\n",
    "    \"ARMCX2\": 35,\n",
    "    \"AURKA\": 36,\n",
    "    \"AURKB\": 37,\n",
    "    \"AXL\": 38,\n",
    "    \"BEX1\": 39,\n",
    "    \"BIRC5\": 40,\n",
    "    \"BMP4\": 41,\n",
    "    \"BUB1\": 42,\n",
    "    \"BUB1B\": 43,\n",
    "    \"CCNA2\": 44,\n",
    "    \"CCND2\": 45,\n",
    "    \"CD40\": 46,\n",
    "    \"CDC20\": 47,\n",
    "    \"CDC42EP1\": 48,\n",
    "    \"CDC45\": 49,\n",
    "    \"CDCA3\": 50,\n",
    "    \"CDCA8\": 51,\n",
    "    \"CDK1\": 52,\n",
    "    \"CDK14\": 53,\n",
    "    \"CDK2\": 54,\n",
    "    \"CDK6\": 55,\n",
    "    \"CENPA\": 56,\n",
    "    \"CKS2\": 57,\n",
    "    \"CLSPN\": 58,\n",
    "    \"CLU\": 59,\n",
    "    \"CNN1\": 60,\n",
    "    \"CRYAB\": 61,\n",
    "    \"CYBA\": 62,\n",
    "    \"DHRS2\": 63,\n",
    "    \"DUSP6\": 64,\n",
    "    \"EEF1A2\": 65,\n",
    "    \"EFEMP1\": 66,\n",
    "    \"EPB41L3\": 67,\n",
    "    \"EXO1\": 68,\n",
    "    \"FEN1\": 69,\n",
    "    \"FGF1\": 70,\n",
    "    \"FGFR2\": 71,\n",
    "    \"FKBP4\": 72,\n",
    "    \"FOS\": 73,\n",
    "    \"FOXM1\": 74,\n",
    "    \"FSTL1\": 75,\n",
    "    \"GTSE1\": 76,\n",
    "    \"HJURP\": 77,\n",
    "    \"HK2\": 78,\n",
    "    \"HSP90AB1\": 79,\n",
    "    \"HSPA1B\": 80,\n",
    "    \"IGF2\": 81,\n",
    "    \"IGFBP5\": 82,\n",
    "    \"INHBA\": 83,\n",
    "    \"KIF2C\": 84,\n",
    "    \"KLK6\": 85,\n",
    "    \"KPNA2\": 86,\n",
    "    \"KRT15\": 87,\n",
    "    \"KRT18\": 88,\n",
    "    \"KRT8\": 89,\n",
    "    \"KRT80\": 90,\n",
    "    \"KRT81\": 91,\n",
    "    \"LBH\": 92,\n",
    "    \"LDOC1\": 93,\n",
    "    \"LGALS1\": 94,\n",
    "    \"LOXL4\": 95,\n",
    "    \"LRP1\": 96,\n",
    "    \"LTBP2\": 97,\n",
    "    \"LZTS2\": 98,\n",
    "    \"MAGEA1\": 99,\n",
    "    \"MAGEA4\": 100,\n",
    "    \"MAGED1\": 101,\n",
    "    \"MAPK8\": 102,\n",
    "    \"MBP\": 103,\n",
    "    \"MCM10\": 104,\n",
    "    \"MCM3\": 105,\n",
    "    \"MCM5\": 106,\n",
    "    \"MCM7\": 107,\n",
    "    \"MDFI\": 108,\n",
    "    \"MDK\": 109,\n",
    "    \"MSH2\": 110,\n",
    "    \"MYH9\": 111,\n",
    "    \"MYL2\": 112,\n",
    "    \"NCF2\": 113,\n",
    "    \"NDC80\": 114,\n",
    "    \"NDN\": 115,\n",
    "    \"NEFL\": 116,\n",
    "    \"NEK2\": 117,\n",
    "    \"NUF2\": 118,\n",
    "    \"PAK2\": 119,\n",
    "    \"PCLO\": 120,\n",
    "    \"PCNA\": 121,\n",
    "    \"PDGFRB\": 122,\n",
    "    \"PLAT\": 123,\n",
    "    \"PLK1\": 124,\n",
    "    \"PRAME\": 125,\n",
    "    \"PRC1\": 126,\n",
    "    \"PRKCA\": 127,\n",
    "    \"PRSS23\": 128,\n",
    "    \"PTCH1\": 129,\n",
    "    \"RACGAP1\": 130,\n",
    "    \"RARA\": 131,\n",
    "    \"RPS6KB1\": 132,\n",
    "    \"RRM2\": 133,\n",
    "    \"S100A14\": 134,\n",
    "    \"SDC1\": 135,\n",
    "    \"SDC2\": 136,\n",
    "    \"SDC3\": 137,\n",
    "    \"SERPINE1\": 138,\n",
    "    \"SFN\": 139,\n",
    "    \"SKP2\": 140,\n",
    "    \"SPARC\": 141,\n",
    "    \"SPC24\": 142,\n",
    "    \"SPC25\": 143,\n",
    "    \"STAC\": 144,\n",
    "    \"STC2\": 145,\n",
    "    \"SUV39H1\": 146,\n",
    "    \"TCF4\": 147,\n",
    "    \"TGFB1\": 148,\n",
    "    \"TGM2\": 149,\n",
    "    \"THRA\": 150,\n",
    "    \"THY1\": 151,\n",
    "    \"TIMP1\": 152,\n",
    "    \"TINAGL1\": 153,\n",
    "    \"TK1\": 154,\n",
    "    \"TNC\": 155,\n",
    "    \"TNNC1\": 156,\n",
    "    \"TNNT1\": 157,\n",
    "    \"TNNT2\": 158,\n",
    "    \"TONSL\": 159,\n",
    "    \"TPM1\": 160,\n",
    "    \"TPM2\": 161,\n",
    "    \"TPX2\": 162,\n",
    "    \"TRIB3\": 163,\n",
    "    \"TTK\": 164,\n",
    "    \"TUBA1A\": 165,\n",
    "    \"TUBB\": 166,\n",
    "    \"TUBB2B\": 167,\n",
    "    \"TUBB6\": 168,\n",
    "    \"UBE2S\": 169,\n",
    "    \"UCHL5\": 170,\n",
    "    \"VCAN\": 171,\n",
    "    \"VIM\": 172,\n",
    "    \"YES1\": 173,\n",
    "    \"YWHAQ\": 174,\n",
    "    \"ZWINT\": 175,\n",
    "}\n",
    "\n",
    "label_dict = dict(zip(list(label_dict.values()), list(label_dict.keys())))\n",
    "jump_img_embs.loc[:, \"labels\"] = np.array(jump_img_embs.labels.map(label_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6415bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idc = np.array(jump_img_embs.index)\n",
    "source = []\n",
    "batch = []\n",
    "plate = []\n",
    "well = []\n",
    "exp_well = []\n",
    "for idx in tqdm(idc):\n",
    "    s = idx.split(\"_\")\n",
    "    source.append(\"_\".join(s[0:2]))\n",
    "    batch.append(\"_\".join(s[2:6]))\n",
    "    plate.append(\"_\".join(s[7]))\n",
    "    well.append(\"_\".join(s[8]))\n",
    "    exp_well.append(\"_\".join(s[:8]))\n",
    "jump_img_embs[\"batch\"] = np.array(batch)\n",
    "jump_img_embs[\"plate\"] = np.array(plate)\n",
    "jump_img_embs[\"well\"] = np.array(well)\n",
    "jump_img_embs[\"exp_well\"] = np.array(exp_well)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494dc72",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1feb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "rohban_img_embs = pd.read_hdf(\n",
    "    \"../../../data/experiments/rohban/images/embeddings/four_fold_cv/fold_0/test_latents.h5\"\n",
    ")\n",
    "\n",
    "label_dict = {\n",
    "    \"AKT1S1\": 0,\n",
    "    \"ATF4\": 1,\n",
    "    \"BAX\": 2,\n",
    "    \"BCL2L11\": 3,\n",
    "    \"BRAF\": 4,\n",
    "    \"CASP8\": 5,\n",
    "    \"CDC42\": 6,\n",
    "    \"CDKN1A\": 7,\n",
    "    \"CEBPA\": 8,\n",
    "    \"CREB1\": 9,\n",
    "    \"CXXC4\": 10,\n",
    "    \"DIABLO\": 11,\n",
    "    \"E2F1\": 12,\n",
    "    \"ELK1\": 13,\n",
    "    \"EMPTY\": 14,\n",
    "    \"ERG\": 15,\n",
    "    \"FGFR3\": 16,\n",
    "    \"FOXO1\": 17,\n",
    "    \"GLI1\": 18,\n",
    "    \"HRAS\": 19,\n",
    "    \"IRAK4\": 20,\n",
    "    \"JUN\": 21,\n",
    "    \"MAP2K3\": 22,\n",
    "    \"MAP3K2\": 23,\n",
    "    \"MAP3K5\": 24,\n",
    "    \"MAP3K9\": 25,\n",
    "    \"MAPK7\": 26,\n",
    "    \"MOS\": 27,\n",
    "    \"MYD88\": 28,\n",
    "    \"PIK3R2\": 29,\n",
    "    \"PRKACA\": 30,\n",
    "    \"PRKCE\": 31,\n",
    "    \"RAF1\": 32,\n",
    "    \"RELB\": 33,\n",
    "    \"RHOA\": 34,\n",
    "    \"SMAD4\": 35,\n",
    "    \"SMO\": 36,\n",
    "    \"SRC\": 37,\n",
    "    \"SREBF1\": 38,\n",
    "    \"TRAF2\": 39,\n",
    "    \"TSC2\": 40,\n",
    "    \"WWTR1\": 41,\n",
    "}\n",
    "label_dict = dict(zip(list(label_dict.values()), list(label_dict.keys())))\n",
    "rohban_img_embs.loc[:, \"labels\"] = np.array(rohban_img_embs.labels.map(label_dict))\n",
    "mean_rohban_img_embs = rohban_img_embs.groupby(\"labels\").mean()\n",
    "mean_rohban_img_embs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0dc0f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Preprocess profile data\n",
    "\n",
    "We will now preprocess the downloaded profile data. To this end, we will perform similar filtering steps as we had done for the dataset by Rohban et al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d881ce",
   "metadata": {},
   "source": [
    "## Filter out non-DNA related features\n",
    "\n",
    "As a first step, we will subset the profiles to only contain features that can be computed from the DNA channel and are thus related to nuclei. This removes any features from the other 4 channels and other image-level descriptions such as e.g. the background intensity information for the DNA channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_keys = [\"er\", \"mito\", \"phgolgi\", \"agp\", \"rna\", \"cytoplasm\", \"image\", \"cells\"]\n",
    "drop_columns = []\n",
    "for col in morph_profiles.columns:\n",
    "    if any(key in col.lower() for key in filter_keys):\n",
    "        drop_columns.append(col)\n",
    "len(drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_profiles_dna = morph_profiles.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d226c95",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Filter out positional features.\n",
    "\n",
    "The previous filtering step removes 4,589/4,766 features. We next filter out any positional features, i.e. features with positional indicators such as X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b6fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_columns = []\n",
    "for col in morph_profiles_dna.columns:\n",
    "    if \"_x\" in col.lower() or \"_y\" in col.lower():\n",
    "        pos_columns.append(col)\n",
    "len(pos_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e89551",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_profiles_dna = morph_profiles_dna.drop(columns=pos_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27fe0c4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Filter out constant features and incomplete entries\n",
    "\n",
    "The previous filtering reduce the total number of features to removes 171. We will now filter out any features, for which we observe a constant value as well as any rows where any of the features was not measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0247131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(morph_profiles_dna).shape, flush=True)\n",
    "morph_profiles_dna = morph_profiles_dna.loc[\n",
    "    :, (morph_profiles_dna != morph_profiles_dna.iloc[0]).any()\n",
    "]\n",
    "morph_profiles_dna = morph_profiles_dna.dropna()\n",
    "print(np.array(morph_profiles_dna).shape, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e2c0c",
   "metadata": {},
   "source": [
    "This filtering steps removes 2 additional features and 804 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aef874",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exploratory data analyses\n",
    "\n",
    "To get an idea of the dataset characteristics and importantly the similarities of different overexpression conditions, we will perform a number of exploratory data analyses. To this end, we will subset the dataset to the 176 conditions that we will focus on in our consecutive analyses to validate our proposed computational platform called Image2Reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d31b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../../data/other/target_lists/jump_targets.pkl\", \"rb\") as handle:\n",
    "    selected_conditions = sorted(list(pickle.load(handle)) + [\"EMPTY\"])\n",
    "print(selected_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ffc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_morph_profiles = morph_profiles_dna.loc[\n",
    "    morph_profiles_dna.Metadata_Symbol.isin(selected_conditions)\n",
    "]\n",
    "jump_morph_profiles.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99da03f",
   "metadata": {},
   "source": [
    "In total there are 2,305 observations that correspond to the 175 selected overexpression conditions and the one control condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac0894",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## UMAP visualization of the data set.\n",
    "\n",
    "We now visualize the individual overexpression conditions using UMAP plots. In each plot, we will highlight one of the overexpression conditions in color and plot the observations of all other conditions in gray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = jump_morph_profiles._get_numeric_data()\n",
    "labels = jump_morph_profiles.Metadata_Symbol\n",
    "\n",
    "mapper = UMAP(random_state=seed)\n",
    "norm_features = StandardScaler().fit_transform(features)\n",
    "embs = mapper.fit_transform(norm_features)\n",
    "embs = pd.DataFrame(embs, index=features.index, columns=[\"umap_0\", \"umap_1\"])\n",
    "embs[\"label\"] = labels.loc[embs.index]\n",
    "embs[\"plate\"] = jump_morph_profiles.loc[embs.index, \"Metadata_Plate\"]\n",
    "embs[\"well\"] = jump_morph_profiles.loc[embs.index, \"Metadata_Well\"]\n",
    "embs[\"batch\"] = jump_morph_profiles.loc[embs.index, \"Metadata_Batch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[18, 12])\n",
    "ax = sns.scatterplot(\n",
    "    data=embs,\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    ax=ax,\n",
    "    s=16,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00a04e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Analyses of batch effects\n",
    "\n",
    "### Visualization of the batch effects\n",
    "\n",
    "We notice that samples from the same batch cluster together in the UMAP plot, which indicates the presence of prominent batch effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47949eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12, 8])\n",
    "ax = sns.scatterplot(\n",
    "    data=embs,\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    hue=\"batch\",\n",
    "    ax=ax,\n",
    "    s=6,\n",
    "    palette=\"tab20\",\n",
    "    hue_order=np.unique(embs.batch),\n",
    ")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.legend(title=\"Batch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b37d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12, 8])\n",
    "ax = sns.scatterplot(\n",
    "    data=embs.loc[embs.label == \"EMPTY\"],\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    hue=\"batch\",\n",
    "    ax=ax,\n",
    "    s=6,\n",
    "    palette=\"tab20\",\n",
    "    hue_order=np.unique(embs.batch),\n",
    ")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.legend(title=\"Batch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509e545a",
   "metadata": {},
   "source": [
    "This shows the presence of dominant batch effects. Since the morphological profiles were computed based on the features we considered, these batch effects might confound our analyses in terms of the similarity of the chromatin states in the different overexpression conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade392ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Different OE conditions in the batches\n",
    "\n",
    "We notice that not all of the overexpression conditions were assessed in each batch, but only a subset of our selected OE conditions was targeted in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b2431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_batch = jump_morph_profiles.groupby(\"Metadata_Batch\").Metadata_Symbol.nunique()\n",
    "per_batch = pd.DataFrame(\n",
    "    np.array(per_batch), index=per_batch.index, columns=[\"n_conditions\"]\n",
    ")\n",
    "per_batch[\"batch\"] = np.array(per_batch.index)\n",
    "per_batch[\"frac_conditions\"] = per_batch.n_conditions / len(\n",
    "    set(jump_morph_profiles.Metadata_Symbol)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ad0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[6, 4])\n",
    "ax = sns.barplot(data=per_batch, x=\"batch\", y=\"frac_conditions\", palette=[\"b\"])\n",
    "ax.set_ylabel(\"Coverage of selected conditions\")\n",
    "ax.set_xlabel(\"Batch\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2e005",
   "metadata": {},
   "source": [
    "As we see the maximum number of the considered 176 condition that is covered by an individual batch is 15,9%, which correspond to 28 of the 176 conditions. Subsetting the data such that we only use data of a single batch is thus no feasible option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb81b12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Different specific targets in the batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08410d",
   "metadata": {},
   "source": [
    "Naively one could circumvent the problems of the different batch effects of simply executing our pipeline individually for each batch data. However, we see that only a very small fraction of the overall small number of specific targets is in each batch, which would make it difficult for the pipeline to generalize to new unseen conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf6031",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_batch_spec = (\n",
    "    jump_morph_profiles.loc[\n",
    "        jump_morph_profiles.Metadata_Symbol.isin(impactful_conditions)\n",
    "    ]\n",
    "    .groupby(\"Metadata_Batch\")\n",
    "    .Metadata_Symbol.nunique()\n",
    ")\n",
    "per_batch_spec = pd.DataFrame(\n",
    "    np.array(per_batch_spec), index=per_batch_spec.index, columns=[\"n_conditions\"]\n",
    ")\n",
    "per_batch_spec[\"batch\"] = np.array(per_batch_spec.index)\n",
    "per_batch_spec[\"frac_conditions\"] = per_batch_spec.n_conditions / len(\n",
    "    set(jump_morph_profiles.Metadata_Symbol)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f092ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[6, 4])\n",
    "ax = sns.barplot(data=per_batch_spec, x=\"batch\", y=\"n_conditions\")\n",
    "ax.set_ylabel(\"Coverage of selected, impactful conditions\")\n",
    "ax.set_xlabel(\"Batch\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f7263",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_batch_spec.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08be11",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Summary of OE condition-batch distribution\n",
    "\n",
    "To better understand which exact OE conditions are grouped in which batch and importantly also which ones are replicated as well as how do the test (non-specific OE) conditions colocalize on a batch level with the training conditions, i.e. the conditions where genes were targeted that we identified to impact the chromatin organization and nuclear morphology of U2OS cells in the data set Rohban. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58247f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_batch_coocc_matrix = pd.DataFrame(\n",
    "    index=sorted(list(selected_conditions)),\n",
    "    columns=np.unique(jump_morph_profiles.Metadata_Batch),\n",
    ")\n",
    "for idx in cond_batch_coocc_matrix.index:\n",
    "    for col in cond_batch_coocc_matrix.columns:\n",
    "        cond_batch_coocc_matrix.loc[idx, col] = int(\n",
    "            (\n",
    "                len(\n",
    "                    jump_morph_profiles.loc[\n",
    "                        (jump_morph_profiles.Metadata_Symbol == idx)\n",
    "                        & (jump_morph_profiles.Metadata_Batch == col)\n",
    "                    ]\n",
    "                )\n",
    "                > 0\n",
    "            )\n",
    "        )\n",
    "cond_batch_coocc_matrix = pd.DataFrame(\n",
    "    np.array(cond_batch_coocc_matrix).astype(int),\n",
    "    index=cond_batch_coocc_matrix.index,\n",
    "    columns=cond_batch_coocc_matrix.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496010eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12, 3])\n",
    "ax = sns.heatmap(\n",
    "    cond_batch_coocc_matrix.transpose().iloc[:, :60],\n",
    "    # row_cluster=False,\n",
    "    # dendrogram_ratio=0.001,\n",
    "    # cbar_pos=None,\n",
    "    # figsize=[12, 4],\n",
    "    ax=ax,\n",
    "    cbar=False,\n",
    "    cmap=\"gray\",\n",
    ")\n",
    "for tick_label in ax.get_xticklabels():\n",
    "    tick_text = tick_label.get_text()\n",
    "    if tick_text in impactful_conditions:\n",
    "        tick_label.set_color(\"r\")\n",
    "        tick_label.set_fontweight(\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12, 3])\n",
    "ax = sns.heatmap(\n",
    "    cond_batch_coocc_matrix.transpose().iloc[:, 60:120],\n",
    "    # row_cluster=False,\n",
    "    # dendrogram_ratio=0.001,\n",
    "    # cbar_pos=None,\n",
    "    # figsize=[12, 4],\n",
    "    ax=ax,\n",
    "    cbar=False,\n",
    "    cmap=\"gray\",\n",
    ")\n",
    "for tick_label in ax.get_xticklabels():\n",
    "    tick_text = tick_label.get_text()\n",
    "    if tick_text in impactful_conditions:\n",
    "        tick_label.set_color(\"r\")\n",
    "        tick_label.set_fontweight(\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12, 3])\n",
    "ax = sns.heatmap(\n",
    "    cond_batch_coocc_matrix.transpose().iloc[:, 120:],\n",
    "    # row_cluster=False,\n",
    "    # dendrogram_ratio=0.001,\n",
    "    # cbar_pos=None,\n",
    "    # figsize=[12, 4],\n",
    "    ax=ax,\n",
    "    cbar=False,\n",
    "    cmap=\"gray\",\n",
    ")\n",
    "for tick_label in ax.get_xticklabels():\n",
    "    tick_text = tick_label.get_text()\n",
    "    if tick_text in impactful_conditions:\n",
    "        tick_label.set_color(\"r\")\n",
    "        tick_label.set_fontweight(\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7ec06",
   "metadata": {},
   "source": [
    "The above map shows that most conditions are not replicated (111/175) or replicated in two batches (43/175) only. Only 22 conditions are replicated in more than 2 batches and solely the control condition is replicated in all batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fda26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(cond_batch_coocc_matrix.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c447279b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d2507",
   "metadata": {},
   "source": [
    "### Characterization of the batch effects\n",
    "\n",
    "#### Prediction of OE condition purely from batch labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = jump_morph_profiles.loc[\n",
    "    jump_morph_profiles.Metadata_Symbol.isin(impactful_conditions)\n",
    "]\n",
    "tmp_labels = np.array(tmp.Metadata_Symbol)\n",
    "tmp_batch_labels = np.array(tmp.Metadata_Batch).reshape(-1, 1)\n",
    "tmp_batch_labels = OneHotEncoder().fit_transform(tmp_batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000,\n",
    "    penalty=\"none\",\n",
    ")\n",
    "\n",
    "bac = cross_val_score(\n",
    "    clf,\n",
    "    tmp_batch_labels,\n",
    "    tmp_labels,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    ")\n",
    "print(bac.mean(), bac.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea14a80",
   "metadata": {},
   "source": [
    "We see that simply by knowing which batch a specific samples comes from a Multinomial regression model can predict the correct overexpression condition with a balanced accuracy of 0.3218 (+/- 0.0212) which is more than half of the performance that we obtained by training the classifier directly on the images. This emphasizes how much information is simply contained in the batch information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346dc1a7",
   "metadata": {},
   "source": [
    "#### RandomForest classification of control samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_profiles = jump_morph_profiles.loc[jump_morph_profiles.Metadata_Symbol == \"EMPTY\"]\n",
    "ctrl_features = ctrl_profiles._get_numeric_data()\n",
    "ctrl_features_norm = StandardScaler().fit_transform(ctrl_features)\n",
    "ctrl_features_norm = pd.DataFrame(\n",
    "    ctrl_features_norm, index=ctrl_features.index, columns=ctrl_features.columns\n",
    ")\n",
    "ctrl_batch_labels = ctrl_profiles.Metadata_Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc50001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=1234)\n",
    "bacs = cross_validate(\n",
    "    rfc,\n",
    "    X=ctrl_features_norm,\n",
    "    y=ctrl_batch_labels,\n",
    "    groups=ctrl_profiles.Metadata_Plate,\n",
    "    cv=StratifiedGroupKFold(n_splits=10),\n",
    "    scoring=\"balanced_accuracy\",\n",
    ")[\"test_score\"]\n",
    "print(\n",
    "    \"Balanced average batch classification accuracy: {} (+/-{})\".format(\n",
    "        np.round(bacs.mean(), 4), np.round(bacs.std(), 4)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e0a1c",
   "metadata": {},
   "source": [
    "First, we find that RFC can distinguish between the different batches of the control cells with an average balanced accuracy of roughly 0.8075 (+/- 0.0393), which is significantly larger than the random baseline equivalent to 0.076. Since the evaluation was done using a stratified group 10-fold cross-validation, where each group was set to the used plate, we also can rule the performance to be impacted by plate effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed93577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = rfc.fit(ctrl_features_norm, ctrl_batch_labels)\n",
    "importances = rfc.feature_importances_\n",
    "importances = pd.DataFrame(\n",
    "    importances, index=ctrl_features_norm.columns, columns=[\"mdi\"]\n",
    ")\n",
    "importances[\"feature\"] = np.array(importances.index)\n",
    "importances = importances.sort_values(\"mdi\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[6, 4])\n",
    "ax = sns.barplot(data=importances.iloc[:15], y=\"feature\", x=\"mdi\", palette=[\"gray\"])\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_xlabel(\"Mean decrease in impurity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6970625",
   "metadata": {},
   "source": [
    "The above feature importance plot indicates that the batch effects are not due to changes of the imaging conditions reflected in differences of intensity-based features such as the texture measurements. Instead,we also observe morphological changes and variability of the spatial DNA organization between the different batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979267b",
   "metadata": {},
   "source": [
    "The boxplots below visualize the differences for 4 chosen morphological profile features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48173b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12, 8], ncols=2, nrows=2, sharex=True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "plot_feats = [\n",
    "    \"Nuclei_AreaShape_Area\",\n",
    "    \"Nuclei_AreaShape_FormFactor\",\n",
    "    \"Nuclei_Granularity_1_DNA\",\n",
    "    \"Nuclei_RadialDistribution_FracAtD_DNA_4of4\",\n",
    "]\n",
    "for i in range(4):\n",
    "    ax[i] = sns.boxplot(\n",
    "        data=ctrl_profiles, x=\"Metadata_Batch\", y=plot_feats[i], ax=ax[i]\n",
    "    )\n",
    "    for tick in ax[i].get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de0ded",
   "metadata": {},
   "source": [
    "Note that these batch effects also persist for any of the other negative controls (eGFP, HcRed, LacZ and Luciferase). There is no condition available where the cells were not treated at all for the JUMP dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54c658b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Linearity of batch effects\n",
    "\n",
    "We next analyze if the batch effects are captured by the principal components of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b70143",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCA(n_components=2)\n",
    "pc_embs = pc.fit_transform(norm_features)\n",
    "pc_embs = pd.DataFrame(pc_embs, index=features.index, columns=[\"pc_0\", \"pc_1\"])\n",
    "pc_embs[\"label\"] = labels.loc[pc_embs.index]\n",
    "pc_embs[\"plate\"] = jump_morph_profiles.loc[pc_embs.index, \"Metadata_Plate\"]\n",
    "pc_embs[\"well\"] = jump_morph_profiles.loc[pc_embs.index, \"Metadata_Well\"]\n",
    "pc_embs[\"batch\"] = jump_morph_profiles.loc[pc_embs.index, \"Metadata_Batch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d96930",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12, 8])\n",
    "ax = sns.scatterplot(\n",
    "    data=pc_embs,\n",
    "    x=\"pc_0\",\n",
    "    y=\"pc_1\",\n",
    "    hue=\"batch\",\n",
    "    s=16,\n",
    "    palette=\"tab20\",\n",
    "    hue_order=np.unique(embs.batch),\n",
    ")\n",
    "ax.set_xlabel(\"PC 0 ({})\".format(np.round(pc.explained_variance_ratio_[0], 4)))\n",
    "ax.set_ylabel(\"PC 1 ({})\".format(np.round(pc.explained_variance_ratio_[1], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1332aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12, 8])\n",
    "ax = sns.scatterplot(\n",
    "    data=pc_embs.loc[pc_embs.label == \"EMPTY\"],\n",
    "    x=\"pc_0\",\n",
    "    y=\"pc_1\",\n",
    "    hue=\"batch\",\n",
    "    s=16,\n",
    "    palette=\"tab20\",\n",
    "    hue_order=np.unique(embs.batch),\n",
    ")\n",
    "ax.set_xlabel(\"PC 0 ({})\".format(np.round(pc.explained_variance_ratio_[0], 4)))\n",
    "ax.set_ylabel(\"PC 1 ({})\".format(np.round(pc.explained_variance_ratio_[1], 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd31e4a",
   "metadata": {},
   "source": [
    "We notice that roughly 78.5% of the total variance of the data is explained by the first two principal components and in particular the first principal component seems to capture the variance from the batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf35ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Comparison to Deep learning embeddings\n",
    "\n",
    "We will now compare that to the embeddings using our proposed image encoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e846d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_image_mean_embs = jump_img_embs.groupby(\"exp_well\").mean(numeric_only=True)\n",
    "jump_image_labels = jump_img_embs.groupby(\"exp_well\").labels.unique()\n",
    "jump_image_labels = pd.Series(\n",
    "    np.concatenate(jump_image_labels), index=jump_image_labels.index\n",
    ")\n",
    "jump_batch_labels = jump_img_embs.groupby(\"exp_well\").batch.unique()\n",
    "jump_batch_labels = pd.Series(\n",
    "    np.concatenate(jump_batch_labels), index=jump_batch_labels.index\n",
    ")\n",
    "jump_plate_labels = jump_img_embs.groupby(\"exp_well\").plate.unique()\n",
    "jump_plate_labels = pd.Series(\n",
    "    np.concatenate(jump_plate_labels), index=jump_plate_labels.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25352ff",
   "metadata": {},
   "source": [
    "To mimic the previous results, we compute an average embedding for each experimental well. We will now visualize the data set using a UMAP plot and highlight the data from the different batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd47a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = UMAP(random_state=seed)\n",
    "jump_umap_embs = mapper.fit_transform(jump_image_mean_embs)\n",
    "jump_umap_embs = pd.DataFrame(\n",
    "    jump_umap_embs, index=jump_image_mean_embs.index, columns=[\"umap_0\", \"umap_1\"]\n",
    ")\n",
    "jump_umap_embs[\"label\"] = jump_image_labels.loc[jump_umap_embs.index]\n",
    "jump_umap_embs[\"plate\"] = jump_plate_labels.loc[jump_umap_embs.index]\n",
    "jump_umap_embs[\"batch\"] = jump_batch_labels.loc[jump_umap_embs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69b9d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12, 8])\n",
    "ax = sns.scatterplot(\n",
    "    data=jump_umap_embs,\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    hue=\"batch\",\n",
    "    ax=ax,\n",
    "    s=6,\n",
    "    palette=\"tab20\",\n",
    "    hue_order=np.unique(embs.batch),\n",
    ")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.legend(title=\"Batch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897853fa",
   "metadata": {},
   "source": [
    "As expected the batch effects are also visible when looking at our deep image embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edcb198",
   "metadata": {},
   "source": [
    "This clearly shows that we need overcome some of these problems with more sophisticated methods to account for the large batch effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f693cc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparison to Rohban et al.\n",
    "\n",
    "We will now compare both the JUMP image embeddings and morphological profiles to what we have seen for the dataset from Rohban et al (2017). To visualize the (dis)similarity we will cluster all by-condition averaged feature representations to the ones obtained for Rohban et al using a co-cluster map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_jump_morph_profiles = jump_morph_profiles.groupby(\"Metadata_Symbol\").mean()\n",
    "compare_clustering_to_rohban(\n",
    "    mean_jump_morph_profiles,\n",
    "    mean_rohban_img_embs,\n",
    "    metric=\"euclidean\",\n",
    "    method=\"complete\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345e141",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814dfbf2",
   "metadata": {},
   "source": [
    "# Overcoming the batch effects\n",
    "\n",
    "Based on the previous results, it is obvious that we need to apply methods to reduce the variability of the data due to the different batches. In particular, we propose the following strategies to obtain chromatin image embeddings that capture the differences of the chromatin states due to the different overexpression rather than the different batch effects:\n",
    "1. Remove the 4 batches that show the largest inter-bach variability: Batch 3,4,10 and 13 and train our model solely based on the models solely based on data of the other batches.\n",
    "2. Perform iterative null-space projection of the obtained embeddings to project the data on a space that does not contain batch information, but hopefully maintains batch-independent information about the chromatin states of the cells in the different overexpression conditions.\n",
    "3. While training the classifier provide the batch information as an additional feature before the final layer to make the classifier use the image embeddings to derive features related to the OE conditions.\n",
    "4. Normalize the embeddings by subtracting each embedding by the mean embedding of the control setting in the corresponding batch.\n",
    "\n",
    "While we will analyze the effect of those steps in more detail in another notebook, we here will exemplarly show the results of the application of the steps 2 and 4. on the morphological profiles.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e8970",
   "metadata": {},
   "source": [
    "## Remove outlier batches\n",
    "\n",
    "As a first step, we will remove the previously mentioned four batches that look very dissimilar from the others and assess which effect that has on the number of impactful and covered gene settings.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41377a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_batches = [\n",
    "    \"2021_05_10_Batch3\",\n",
    "    \"2021_05_17_Batch4\",\n",
    "    \"2021_08_02_Batch10\",\n",
    "    \"2021_08_30_Batch13\",\n",
    "]\n",
    "\n",
    "outlier_orf_data = all_orf_data.loc[all_orf_data.Metadata_Batch.isin(outlier_batches)]\n",
    "other_orf_data = all_orf_data.loc[~all_orf_data.Metadata_Batch.isin(outlier_batches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62405e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_targets = set(outlier_orf_data.Metadata_Symbol)\n",
    "other_targets = set(other_orf_data.Metadata_Symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96135c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "venn(\n",
    "    {\n",
    "        \"Conditions in outlier batches\": outlier_targets,\n",
    "        \"Conditions in other batches\": other_targets,\n",
    "        \"Impactful conditions\": set(impactful_conditions),\n",
    "        \"Conditions covered by the GGI\": set(selected_conditions),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70d576",
   "metadata": {},
   "source": [
    "We notice that by removing those four batches we eventually loose coverage of 27/175 including 5/33 impactful gene perturbation settings. The conditions we loose are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc99cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Lost impactful gene targets:\",\n",
    "    outlier_targets.intersection(impactful_conditions) - other_targets,\n",
    ")\n",
    "print(\n",
    "    \"Lost gene targets covered in GGI (prediction candidates):\",\n",
    "    outlier_targets.intersection(selected_conditions) - other_targets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8acd0",
   "metadata": {},
   "source": [
    "Unfortunately, three of the 5 impactful condition that are only contained in the identified outlier batches are CXXC4, BCL2L11 and CASP8 all three were observed to be highly toxic upon overexpression in the previous study by Rohban et al. Not having those genes is likely to reduce our coverage of the chromatin states of cells for overexpression settings related to the cellular apoptosis pathway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd52134",
   "metadata": {},
   "source": [
    "However, only CASP8 would be additionally covered of those three if we would restrict ourselves to only removing the two batches that showed the strongest batch effects namely Batch 3 and 4. Thus, for now we will proceed with only using the other 9 batches, that are not Batch 3,4,10 or 13."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3252f81c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10505355",
   "metadata": {},
   "source": [
    "## Batch-specific normalization.\n",
    "\n",
    "As alternative or addition to the batch subsetting, we also could normalize the morphological profiles by computing the mean and the standard deviation for the control setting for each batch or even for each plate individually and normalize the the morphological profiles in a given batch or plate by the respective statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8025c29",
   "metadata": {},
   "source": [
    "### Morphological profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10790c56",
   "metadata": {},
   "source": [
    "We first assess the performance of normalizing the embeddings by centering them to the average of the mean conditions in each batch for the morphological profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3bf627",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_morph_profiles_bc = do_within_batch_normalization(jump_morph_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_morph_profiles_bc[\"plate\"] = jump_morph_profiles.loc[\n",
    "    jump_morph_profiles_bc.index, \"Metadata_Plate\"\n",
    "]\n",
    "jump_morph_profiles_bc[\"well\"] = jump_morph_profiles.loc[\n",
    "    jump_morph_profiles_bc.index, \"Metadata_Well\"\n",
    "]\n",
    "jump_morph_profiles_bc[\"batch\"] = jump_morph_profiles.loc[\n",
    "    jump_morph_profiles_bc.index, \"Metadata_Batch\"\n",
    "]\n",
    "jump_morph_profiles_bc[\"label\"] = jump_morph_profiles.loc[\n",
    "    jump_morph_profiles_bc.index, \"Metadata_Symbol\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f797b",
   "metadata": {},
   "source": [
    "Let us now check how the scaled data looks in UMAP space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = jump_morph_profiles_bc._get_numeric_data()\n",
    "labels = jump_morph_profiles_bc.label\n",
    "\n",
    "mapper = UMAP(random_state=seed)\n",
    "norm_features = StandardScaler().fit_transform(features)\n",
    "embs = mapper.fit_transform(norm_features)\n",
    "embs = pd.DataFrame(embs, index=features.index, columns=[\"umap_0\", \"umap_1\"])\n",
    "embs[\"label\"] = labels.loc[embs.index]\n",
    "embs[\"plate\"] = jump_morph_profiles_bc.loc[embs.index, \"plate\"]\n",
    "embs[\"well\"] = jump_morph_profiles_bc.loc[embs.index, \"well\"]\n",
    "embs[\"batch\"] = jump_morph_profiles_bc.loc[embs.index, \"batch\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[12, 8])\n",
    "ax = sns.scatterplot(\n",
    "    data=embs,\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    hue=\"batch\",\n",
    "    ax=ax,\n",
    "    s=16,\n",
    "    palette=\"tab20\",\n",
    "    hue_order=np.unique(embs.batch),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ed4b9",
   "metadata": {},
   "source": [
    "\n",
    "The UMAP plot suggests that the scale of the batch effects could be effectively reduced using the normalization approach. However, to check the strength of the batch effects, we will also look at the classification performance of multinomial regression model using the centered data to predict the corresponding batch labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1100f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_profiles_bc = jump_morph_profiles_bc.loc[\n",
    "    jump_morph_profiles_bc.Metadata_Symbol == \"EMPTY\"\n",
    "]\n",
    "ctrl_features_bc = ctrl_profiles_bc._get_numeric_data()\n",
    "ctrl_features_bc_norm = StandardScaler().fit_transform(ctrl_features_bc)\n",
    "ctrl_features_bc_norm = pd.DataFrame(\n",
    "    ctrl_features_bc_norm,\n",
    "    index=ctrl_features_bc.index,\n",
    "    columns=ctrl_features_bc.columns,\n",
    ")\n",
    "ctrl_batch_labels = ctrl_profiles_bc.Metadata_Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a60ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=1234)\n",
    "bacs = cross_validate(\n",
    "    rfc,\n",
    "    X=ctrl_features_bc_norm,\n",
    "    y=ctrl_batch_labels,\n",
    "    groups=ctrl_profiles.Metadata_Plate,\n",
    "    cv=StratifiedGroupKFold(n_splits=10),\n",
    "    scoring=\"balanced_accuracy\",\n",
    ")[\"test_score\"]\n",
    "print(\n",
    "    \"Balanced average batch classification accuracy: {} (+/-{})\".format(\n",
    "        np.round(bacs.mean(), 4), np.round(bacs.std(), 4)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca2241",
   "metadata": {},
   "source": [
    "In agreement with the previous UMAP plot, we observe the classification accuracy of a RandomForest classifier to drop to from 81% to 31% after the centering approach. However, the performance is still roughly 4 times of what we would expect by random chance (i.e. 7.6%), which shows that the centering did not fully resolve the batch problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ae951",
   "metadata": {},
   "source": [
    "We are similarly interested in how similar the overall structure of those embeddings look to what we have observed using our CNN-based image embeddings in the data set from Rohban et al.\n",
    "\n",
    "To assess that we will plot the clustered pair-wise euclidean distance matrix for the two embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_jump_morph_profiles_bc = jump_morph_profiles_bc.groupby(\"label\").mean()\n",
    "compare_clustering_to_rohban(\n",
    "    mean_jump_morph_profiles_bc,\n",
    "    mean_rohban_img_embs,\n",
    "    metric=\"euclidean\",\n",
    "    method=\"complete\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221019e",
   "metadata": {},
   "source": [
    "Looking at the above clustermaps we see that in both embeddings the conditions of JUN and ERG as well as BCL2L11 and CASP8 prominently cluster together. While the other clustering structure looks slighltly different, we also observe genes of the MAPK pathway to cluster together in both the embeddings from Rohban et al as well as the batch-centered morphological profiles from the JUMP data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fffed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Deep image embeddings\n",
    "\n",
    "We next validate if this also holds true using our deep-learning based image embeddings. At first, we will do that on an image level as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c63d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_img_embs_bc = do_within_batch_normalization(\n",
    "    jump_img_embs, batch_col=\"batch\", label_col=\"labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e481bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_image_mean_embs_bc = jump_img_embs_bc.groupby(\"exp_well\").mean(numeric_only=True)\n",
    "jump_image_labels = jump_img_embs_bc.groupby(\"exp_well\").labels.unique()\n",
    "jump_image_labels = pd.Series(\n",
    "    np.concatenate(jump_image_labels), index=jump_image_labels.index\n",
    ")\n",
    "jump_batch_labels = jump_img_embs_bc.groupby(\"exp_well\").batch.unique()\n",
    "jump_batch_labels = pd.Series(\n",
    "    np.concatenate(jump_batch_labels), index=jump_batch_labels.index\n",
    ")\n",
    "jump_plate_labels = jump_img_embs_bc.groupby(\"exp_well\").plate.unique()\n",
    "jump_plate_labels = pd.Series(\n",
    "    np.concatenate(jump_plate_labels), index=jump_plate_labels.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = UMAP(random_state=seed)\n",
    "jump_umap_embs_bc = mapper.fit_transform(jump_image_mean_embs_bc)\n",
    "jump_umap_embs_bc = pd.DataFrame(\n",
    "    jump_umap_embs_bc, index=jump_image_mean_embs_bc.index, columns=[\"umap_0\", \"umap_1\"]\n",
    ")\n",
    "jump_umap_embs_bc[\"label\"] = jump_image_labels.loc[jump_umap_embs_bc.index]\n",
    "jump_umap_embs_bc[\"plate\"] = jump_plate_labels.loc[jump_umap_embs_bc.index]\n",
    "jump_umap_embs_bc[\"batch\"] = jump_batch_labels.loc[jump_umap_embs_bc.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[18, 12])\n",
    "ax = sns.scatterplot(\n",
    "    data=jump_umap_embs_bc,\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    hue=\"batch\",\n",
    "    ax=ax,\n",
    "    s=16,\n",
    "    palette=\"tab20\",\n",
    "    hue_order=np.unique(embs.batch),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4de929",
   "metadata": {},
   "source": [
    "Similarly to the observations for the morphological profiles we observe significantly less batch effects after the normalization. However the samples from batch 3 and 4 still group somewhat differently in addition to a few outliers from batch 12.\n",
    "\n",
    "As before, we next analyze the similarity of the clustering of the batch-centered JUMP image embeddings and the image embeddings from Rohban et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba80d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_jump_img_embs_bc = jump_img_embs_bc.groupby(\"labels\").mean()\n",
    "compare_clustering_to_rohban(\n",
    "    mean_jump_img_embs_bc, mean_rohban_img_embs, metric=\"euclidean\", method=\"complete\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c4979",
   "metadata": {},
   "source": [
    "The clustermap above shows that the batch-centering does not as well preserve the cluster structure that we had previously observed for the dataset from Rohban et al. This can be explained by the fact that since the classifier is trained to distinguish between different conditions and some are present in only a few batches during training the batch effects are enforced and non-linearly reflected in the obtained embeddings as it helps the classifier to identify the corresponding conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c18f676",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eeaf23",
   "metadata": {},
   "source": [
    "## Iterative null-space projection\n",
    "\n",
    "Thus, in particular for the embeddings obtained from our CNN-based methods, more sophisticated methods to remove batch effects are needed. As described before our third approach uses the the iterature null-space projection algorithm.\n",
    "\n",
    "The iterative null-space projection algorithm aims to remove batch effects by repeating the following procedure:\n",
    "\n",
    "1. Given the embedding Z and the corresponding batch labels y, solve a linear model for $ZW^T = y$, where $Z \\in \\mathbb{R}^{n \\times d}, W \\in \\mathbb{R}^{b\\times d}$ and $y \\in \\mathbb{R}^{n\\times b}$\n",
    "2. Decompose $W=U\\Sigma V^T$\n",
    "3. Obtain batch-independent components of $V^T$ as $\\tilde{V}^T$. that correspond to the dimensions multiplied with the 0 singular values.\n",
    "3. Obtain projection of embeddings less dependent on the batch label as $\\tilde{Z} = Z\\tilde{V}$\n",
    "\n",
    "This process is repeated until the linear model in step one can no longer distinguish well between the batches. Note that at each step the dimension is reduced by the number of batches, i.e. $b$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f23100",
   "metadata": {},
   "source": [
    "We implement that now briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3034c3ea",
   "metadata": {},
   "source": [
    "### Morphological profiles\n",
    "\n",
    "We will now experiment how well the method works for the morphological profiles. Note that we will assess the method with and without a preceding batch-specific normalization as described before.\n",
    "\n",
    "For now, we will also not filter out any batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee094fe",
   "metadata": {},
   "source": [
    "Since, we have 13 batches in total, we will set the threshold on the 3-fold cross-validated balanced accuracy to 30% which is marginally above random chance (= 7.6%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecef6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels = jump_morph_profiles.Metadata_Batch\n",
    "features = jump_morph_profiles._get_numeric_data()\n",
    "norm_features = StandardScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4057c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692663ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_morph_profiles_insp, batch_bacs = iterative_null_space_projection(\n",
    "    norm_features, np.array(batch_labels), balance_batches=True\n",
    ")\n",
    "jump_morph_profiles_insp = pd.DataFrame(\n",
    "    jump_morph_profiles_insp, index=jump_morph_profiles.index\n",
    ")\n",
    "jump_morph_profiles_insp[\"batch\"] = np.array(jump_morph_profiles.Metadata_Batch)\n",
    "jump_morph_profiles_insp[\"label\"] = np.array(jump_morph_profiles.Metadata_Symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[6, 4])\n",
    "ax.plot(list(range(len(batch_bacs))), batch_bacs)\n",
    "ax.scatter(list(range(len(batch_bacs))), batch_bacs)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Avg. 3-fold CV BAC\")\n",
    "ax.set_title(\"Evolution of the performance of the batch classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53eaa26",
   "metadata": {},
   "source": [
    "We find that the threshold is hit after 8 iterations of the algorithm. Since at each iteration 13 features are removed the resulting reduced profiles contain 58 features.\n",
    "\n",
    "A UMAP plot validates that the obtained embeddings do not group samples by batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36327bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = UMAP(random_state=seed)\n",
    "embs = mapper.fit_transform(\n",
    "    StandardScaler().fit_transform(jump_morph_profiles_insp._get_numeric_data())\n",
    ")\n",
    "embs = pd.DataFrame(\n",
    "    embs, index=jump_morph_profiles_insp.index, columns=[\"umap_0\", \"umap_1\"]\n",
    ")\n",
    "embs[\"label\"] = jump_morph_profiles.loc[embs.index, \"Metadata_Symbol\"]\n",
    "embs[\"plate\"] = jump_morph_profiles.loc[embs.index, \"Metadata_Plate\"]\n",
    "embs[\"well\"] = jump_morph_profiles.loc[embs.index, \"Metadata_Well\"]\n",
    "embs[\"batch\"] = jump_morph_profiles.loc[embs.index, \"Metadata_Batch\"]\n",
    "fig, ax = plt.subplots(figsize=[12, 8])\n",
    "ax = sns.scatterplot(\n",
    "    data=embs, x=\"umap_0\", y=\"umap_1\", hue=\"batch\", ax=ax, s=16, palette=\"tab20\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abbd7fa",
   "metadata": {},
   "source": [
    "As seen above by the plot, the method indeed removes any kind of batch information from the data.\n",
    "\n",
    "We next check if it however maintains the biological information regarding the similarities of certain OE conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_jump_morph_profiles_insp = jump_morph_profiles_insp.groupby(\"label\").mean()\n",
    "compare_clustering_to_rohban(\n",
    "    mean_jump_morph_profiles_insp, mean_rohban_img_embs, metric=\"euclidean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f139e",
   "metadata": {},
   "source": [
    "In contrast to what we had seen for the batch-centered profiles, the embeddings we obtain as a result of the INSP directly used on the learned features seem to not reflect the cluster structure we had found in the data set by Rohban et al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad73b0d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Deep image embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d5246f",
   "metadata": {},
   "source": [
    "We now check the effect of the INSP on the embeddings using our obtained image embeddings for the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db265d",
   "metadata": {},
   "source": [
    "Since, we have 13 batches in total, we will set the threshold on the 3-fold cross-validated balanced accuracy to 10% which is marginally above random chance (= 7.6%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcf60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels = jump_img_embs.batch\n",
    "features = jump_img_embs._get_numeric_data()\n",
    "norm_features = StandardScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_img_embs_insp, batch_bacs = iterative_null_space_projection(\n",
    "    norm_features,\n",
    "    np.array(batch_labels),\n",
    "    n_jobs=10,\n",
    "    max_iter_clf=10,\n",
    "    balance_batches=True,\n",
    "    n_samples_per_batch=10000,\n",
    ")\n",
    "jump_img_embs_insp = pd.DataFrame(jump_img_embs_insp, index=jump_img_embs.index)\n",
    "jump_img_embs_insp[\"batch\"] = np.array(jump_img_embs.batch)\n",
    "jump_img_embs_insp[\"label\"] = np.array(jump_img_embs.labels)\n",
    "jump_img_embs_insp[\"exp_well\"] = np.array(jump_img_embs.exp_well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[6, 4])\n",
    "ax.plot(list(range(len(batch_bacs))), batch_bacs)\n",
    "ax.scatter(list(range(len(batch_bacs))), batch_bacs)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Avg. 3-fold CV BAC\")\n",
    "ax.set_title(\"Evolution of the performance of the batch classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edae081",
   "metadata": {},
   "source": [
    "We find that the threshold is hit after 5 iterations of the algorithm. Since at each iteration 13 features are removed the resulting reduced profiles contain 1024-65 features.\n",
    "\n",
    "A UMAP plot validates that the obtained embeddings do not group samples by batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec13737",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_image_mean_embs_insp = jump_img_embs_insp.groupby(\"exp_well\").mean(\n",
    "    numeric_only=True\n",
    ")\n",
    "jump_image_labels = jump_img_embs_insp.groupby(\"exp_well\").label.unique()\n",
    "jump_image_labels = pd.Series(\n",
    "    np.concatenate(jump_image_labels), index=jump_image_labels.index\n",
    ")\n",
    "jump_batch_labels = jump_img_embs_insp.groupby(\"exp_well\").batch.unique()\n",
    "jump_batch_labels = pd.Series(\n",
    "    np.concatenate(jump_batch_labels), index=jump_batch_labels.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = UMAP(random_state=seed)\n",
    "jump_umap_embs_insp = mapper.fit_transform(jump_image_mean_embs_insp)\n",
    "jump_umap_embs_insp = pd.DataFrame(\n",
    "    jump_umap_embs_insp,\n",
    "    index=jump_image_mean_embs_insp.index,\n",
    "    columns=[\"umap_0\", \"umap_1\"],\n",
    ")\n",
    "jump_umap_embs_insp[\"label\"] = jump_image_labels.loc[jump_umap_embs_bc.index]\n",
    "jump_umap_embs_insp[\"batch\"] = jump_batch_labels.loc[jump_umap_embs_bc.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d19100",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[18, 12])\n",
    "ax = sns.scatterplot(\n",
    "    data=jump_umap_embs_insp,\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    hue=\"batch\",\n",
    "    ax=ax,\n",
    "    s=16,\n",
    "    palette=\"tab20\",\n",
    "    hue_order=np.unique(embs.batch),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d6b68",
   "metadata": {},
   "source": [
    "As seen above by the plot, the method indeed removes any kind of batch information from the data.\n",
    "\n",
    "We next check if it however maintains the biological information regarding the similarities of certain OE conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_jump_img_embs_insp = jump_img_embs_insp.groupby(\"label\").mean()\n",
    "compare_clustering_to_rohban(\n",
    "    mean_jump_img_embs_insp, mean_rohban_img_embs, metric=\"euclidean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76ce8e",
   "metadata": {},
   "source": [
    "While the profiles at least highlight the most obvious cluster that is the one of CASP8 and BCL2L11 it does not as clearly show the clustering of JUN and ERG or the genes of the MAPK signaling pathways as e.g. the batch-centered profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6853b41d",
   "metadata": {},
   "source": [
    "# Data export\n",
    "\n",
    "We will now export the data for it to be used in later analyses."
   ]
  },
  {
   "cell_type": "raw",
   "id": "086ec1de",
   "metadata": {},
   "source": [
    "jump_img_embs.to_hdf(os.path.join(emb_output_dir, \"jump_img_embs.h5\"), key=\"data\")\n",
    "jump_img_embs_bc.to_hdf(os.path.join(emb_output_dir, \"jump_img_embs_bc.h5\"), key=\"data\")\n",
    "jump_img_embs_insp.to_hdf(\n",
    "    os.path.join(emb_output_dir, \"jump_img_embs_insp.h5\"), key=\"data\"\n",
    ")\n",
    "\n",
    "jump_morph_profiles.to_hdf(\n",
    "    os.path.join(emb_output_dir, \"jump_morph_profiles.h5\"), key=\"data\"\n",
    ")\n",
    "jump_morph_profiles_bc.to_hdf(\n",
    "    os.path.join(emb_output_dir, \"jump_morph_profiles_bc.h5\"), key=\"data\"\n",
    ")\n",
    "jump_morph_profiles_insp.to_hdf(\n",
    "    os.path.join(emb_output_dir, \"jump_morph_profiles_insp.h5\"), key=\"data\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "626.667px",
    "left": "22px",
    "top": "140px",
    "width": "308px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
